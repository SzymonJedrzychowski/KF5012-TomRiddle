{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdcnsXiXWsEV"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import sklearn.model_selection\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsCTG0GpupVL"
      },
      "outputs": [],
      "source": [
        "#For the program to work, data needs to be downloaded (https://drive.google.com/file/d/1hgXutPsaBE7yhqKjMwKy1OtvVQHV4XXk/view?usp=sharing - this is updated file with new photos).\n",
        "#It was found that some problems with uploading big amounts of photos my cause the colab to stop working. The best way to upload photos, is to download the .zip file and upload it\n",
        "#to google drive and use colab api to get the data from the .zip file.\n",
        "#Please, upload the zip file to main directory of your google drive (if not possible, then please change code in next code block).\n",
        "\n",
        "def createDirectories():\n",
        "  #Directories structure (it is checked if directory already exists in order not to erase uploaded images):\n",
        "  drive.mount('drive')\n",
        "  \n",
        "  if not os.path.isdir(\"processedData\"):\n",
        "    os.mkdir(\"processedData\")\n",
        "    \n",
        "createDirectories()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDDTqF_lHAXJ"
      },
      "outputs": [],
      "source": [
        "#This command will extract all the files from .zip file and move them to new directories.\n",
        "#Please check if the location of the file in this code is correct with the location where you uploaded the code on personal google drive.\n",
        "!unzip drive/MyDrive/updatedData.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NE7xk3kbmdA"
      },
      "outputs": [],
      "source": [
        "def preprocessImages(img_cols, img_rows):\n",
        "  #Load data, modify files and save them (COVID)\n",
        "  for i, fileName in enumerate(os.listdir(\"updatedData/CT_COVID\")):\n",
        "    image = Image.open(\"updatedData/CT_COVID/{}\".format(fileName)) #load\n",
        "    resizedImage = image.resize((img_cols, img_rows)) #resize\n",
        "    grayImage = ImageOps.grayscale(resizedImage) #grayscale\n",
        "    grayImage.save(\"processedData/COVID_{}.jpg\".format(i)) #save\n",
        "\n",
        "  #Load data, modify files and save them (NonCOVID)\n",
        "  for i, fileName in enumerate(os.listdir(\"updatedData/CT_NonCOVID\")):\n",
        "    image = Image.open(\"updatedData/CT_NonCOVID/{}\".format(fileName)) #load\n",
        "    resizedImage = image.resize((img_cols, img_rows)) #resize\n",
        "    grayImage = ImageOps.grayscale(resizedImage) #grayscale\n",
        "    grayImage.save(\"processedData/NonCOVID_{}.jpg\".format(i)) #save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGoxbQm3inFD"
      },
      "outputs": [],
      "source": [
        "def createNumpyData(num_classes):\n",
        "  xData = []\n",
        "  yData = []\n",
        "  #Load processed data and append values to arrays\n",
        "  for fileName in os.listdir(\"processedData\"):\n",
        "    image = Image.open('processedData/{}'.format(fileName))\n",
        "    xData.append(np.asarray(image))\n",
        "    if fileName[0] == \"C\":\n",
        "      yData.append(1)\n",
        "    else:\n",
        "      yData.append(0)\n",
        "  \n",
        "  #Convert python array to numpy array\n",
        "  xNumpyData = np.array(xData)\n",
        "  yNumpyData = np.array(yData)\n",
        "  \n",
        "  #Convert pixel values to values between 0 and 1\n",
        "  xNumpyData = xNumpyData.astype('float32')\n",
        "  xNumpyData /= 255\n",
        "  \n",
        "  #Assign classes for yData\n",
        "  yNumpyData = np_utils.to_categorical(yNumpyData, num_classes)\n",
        "\n",
        "  return xNumpyData, yNumpyData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDNCojb0hkvI"
      },
      "outputs": [],
      "source": [
        "def splitData(xNumpyData, yNumpyData, test_size, img_cols, img_rows):\n",
        "  #Split the data\n",
        "  x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(xNumpyData, yNumpyData, test_size=0.1, random_state=42)\n",
        "  #Reshape the xData (gray scale is used so only 1 number needed to describe each pixel)\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_cols, img_rows, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_cols, img_rows, 1)\n",
        "  input_shape = (img_cols, img_rows, 1)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOuBJey8pvm6"
      },
      "outputs": [],
      "source": [
        "#Specify image size and process the images to vectors\n",
        "img_cols, img_rows = 140, 100\n",
        "num_classes = 2\n",
        "\n",
        "preprocessImages(img_cols, img_rows)\n",
        "xNumpyData, yNumpyData = createNumpyData(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1F0j5oh_L0S"
      },
      "outputs": [],
      "source": [
        "def createDeepModel(input_shape, num_classes):\n",
        "  #Create deep model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape, padding='same')) \n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(num_classes, activation='softmax')) \n",
        "  model.summary()\n",
        "  model.compile(loss=binary_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co_k0L4r9nZn"
      },
      "outputs": [],
      "source": [
        "def trainModelAugumented(model, x_train, y_train, x_test, y_test, batch_size, epochs):    \n",
        "  datagen = ImageDataGenerator(\n",
        "      #Rotate images up to specified value\n",
        "      rotation_range=15,\n",
        "      #Random vertical and horizontal shift up to specified value\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      #Zoom up to specified value\n",
        "      zoom_range=0.2,\n",
        "      #Allow horizontal flip but not vertical\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False)\n",
        "\n",
        "  datagen.fit(x_train)\n",
        "  #Apply augumentation and train the model\n",
        "  model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            validation_data=(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmh9e4yTlUHv"
      },
      "outputs": [],
      "source": [
        "def createModel(input_shape, num_classes): \n",
        "  #Create model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.summary()\n",
        "  model.compile(loss=binary_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8pmrEsem5Mh"
      },
      "outputs": [],
      "source": [
        "def trainModel(model, x_train, y_train, x_test, y_test, batch_size, epochs):\n",
        "  model.fit(x_train, y_train, batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            validation_data=(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9ZV9jeiq4zg"
      },
      "outputs": [],
      "source": [
        "#Specify test size and split the data\n",
        "test_size = 0.1\n",
        "x_train, x_val, y_train, y_val, input_shape = splitData(xNumpyData, yNumpyData, test_size, img_cols, img_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fykVztgonI5o"
      },
      "outputs": [],
      "source": [
        "#Specify learning parameters and fit the model\n",
        "batch_size = 32\n",
        "epochs = 12\n",
        "\n",
        "model = createModel(input_shape, num_classes)\n",
        "trainModel(model, x_train, y_train, x_val, y_val, batch_size, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yngx0uHf53e_"
      },
      "outputs": [],
      "source": [
        "#Save model for GUI implementation\n",
        "model.save(\"model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUzV6uRbTZeM"
      },
      "outputs": [],
      "source": [
        "#ZIP the model so it can be downloaded\n",
        "!zip -r model.zip model/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IterativeDevelopment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}