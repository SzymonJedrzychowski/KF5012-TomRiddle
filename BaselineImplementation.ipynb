{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineImplementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMHxCCFvBzeq"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import sklearn.model_selection\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For the program to work, data needs to be downloaded (https://drive.google.com/file/d/1A3dvLECp6Qva4F3jsYWUL3IXcwqJM4Wj/view?usp=sharing) and loaded after directories are created.\n",
        "\n",
        "def createDirectories():\n",
        "  #Directories structure (it is checked if directory already exists in order not to erase uploaded images):\n",
        "  if not os.path.isdir(\"baseData\"):\n",
        "    os.mkdir(\"baseData\")\n",
        "  \n",
        "  #All images should be uploaded to respective directories (CT_COVID or CT_NonCOVID)\n",
        "  if not os.path.isdir(\"baseData/CT_COVID\"):\n",
        "    \n",
        "    os.mkdir(\"baseData/CT_COVID\")\n",
        "  if not os.path.isdir(\"baseData/CT_NonCOVID\"):\n",
        "    os.mkdir(\"baseData/CT_NonCOVID\")\n",
        "  \n",
        "  if not os.path.isdir(\"processedData\"):\n",
        "    os.mkdir(\"processedData\")\n",
        "    \n",
        "createDirectories()"
      ],
      "metadata": {
        "id": "wivdQ-7wBze8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessImages(img_cols, img_rows):\n",
        "  #Load data, modify files and save them (COVID)\n",
        "  for i, fileName in enumerate(os.listdir(\"baseData/CT_COVID\")):\n",
        "    image = Image.open(\"baseData/CT_COVID/{}\".format(fileName)) #load\n",
        "    resizedImage = image.resize((img_cols, img_rows)) #resize\n",
        "    grayImage = ImageOps.grayscale(resizedImage) #grayscale\n",
        "    grayImage.save(\"processedData/COVID_{}.jpg\".format(i)) #save\n",
        "\n",
        "  #Load data, modify files and save them (NonCOVID)\n",
        "  for i, fileName in enumerate(os.listdir(\"baseData/CT_NonCOVID\")):\n",
        "    image = Image.open(\"baseData/CT_NonCOVID/{}\".format(fileName)) #load\n",
        "    resizedImage = image.resize((img_cols, img_rows)) #resize\n",
        "    grayImage = ImageOps.grayscale(resizedImage) #grayscale\n",
        "    grayImage.save(\"processedData/NonCOVID_{}.jpg\".format(i)) #save"
      ],
      "metadata": {
        "id": "iGoxbQm3inFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createNumpyData(num_classes):\n",
        "  xData = []\n",
        "  yData = []\n",
        "  #Load processed data and append values to arrays\n",
        "  for fileName in os.listdir(\"processedData\"):\n",
        "    image = Image.open('processedData/{}'.format(fileName))\n",
        "    xData.append(np.asarray(image))\n",
        "    if fileName[0] == \"C\":\n",
        "      yData.append(1)\n",
        "    else:\n",
        "      yData.append(0)\n",
        "  \n",
        "  #Convert python array to numpy array\n",
        "  xNumpyData = np.array(xData)\n",
        "  yNumpyData = np.array(yData)\n",
        "  \n",
        "  #Convert pixel values to values between 0 and 1\n",
        "  xNumpyData = xNumpyData.astype('float32')\n",
        "  xNumpyData /= 255\n",
        "  \n",
        "  #Assign classes for yData\n",
        "  yNumpyData = np_utils.to_categorical(yNumpyData, num_classes)\n",
        "\n",
        "  return xNumpyData, yNumpyData"
      ],
      "metadata": {
        "id": "MZW5ZO56Bze9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def splitData(xNumpyData, yNumpyData, test_size, img_cols, img_rows):\n",
        "  #Split the data\n",
        "  x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(xNumpyData, yNumpyData, test_size=0.1, random_state=42)\n",
        "  #Reshape the xData (gray scale is used so only 1 number needed to describe each pixel)\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_cols, img_rows, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_cols, img_rows, 1)\n",
        "  input_shape = (img_cols, img_rows, 1)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, input_shape"
      ],
      "metadata": {
        "id": "BiBKmNhhBze9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify image size and process the images to vectors\n",
        "img_cols, img_rows = 140, 100\n",
        "num_classes = 2\n",
        "\n",
        "preprocessImages(img_cols, img_rows)\n",
        "xNumpyData, yNumpyData = createNumpyData(num_classes)"
      ],
      "metadata": {
        "id": "m9StxtvCCu_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify test size and split the data\n",
        "test_size = 0.1\n",
        "x_train, x_test, y_train, y_test, input_shape = splitData(xNumpyData, yNumpyData, test_size, img_cols, img_rows)"
      ],
      "metadata": {
        "id": "kYwPjiv2EqaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel(input_shape, num_classes): \n",
        "  #Create model\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                   activation='relu',\n",
        "                   input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "  model.summary()\n",
        "  model.compile(loss=categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "smWSii5zBze-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testModel(model, x_train, y_train, x_test, y_test, batch_size, epochs):\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            validation_data=(x_test, y_test))\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  return score"
      ],
      "metadata": {
        "id": "9VzFD9S1Bze_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Specify learning parameters and fit the model\n",
        "batch_size = 32\n",
        "epochs = 12\n",
        "\n",
        "model = createModel(input_shape, num_classes)\n",
        "testModel(model, x_train, y_train, x_test, y_test, batch_size, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It0T1Xs-E5nV",
        "outputId": "cb1fecef-ee24-480c-dea5-bc190d0a2e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 138, 98, 32)       320       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 136, 96, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 68, 48, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 68, 48, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 208896)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               26738816  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,757,890\n",
            "Trainable params: 26,757,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "21/21 [==============================] - 2s 89ms/step - loss: 2.0574 - accuracy: 0.5186 - val_loss: 0.6400 - val_accuracy: 0.5867\n",
            "Epoch 2/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.6516 - accuracy: 0.5902 - val_loss: 0.6735 - val_accuracy: 0.6533\n",
            "Epoch 3/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.5523 - accuracy: 0.7183 - val_loss: 0.5861 - val_accuracy: 0.7333\n",
            "Epoch 4/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.4470 - accuracy: 0.7824 - val_loss: 0.5170 - val_accuracy: 0.7067\n",
            "Epoch 5/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3776 - accuracy: 0.8331 - val_loss: 0.4697 - val_accuracy: 0.7733\n",
            "Epoch 6/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.3170 - accuracy: 0.8659 - val_loss: 0.7122 - val_accuracy: 0.6933\n",
            "Epoch 7/12\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.2670 - accuracy: 0.8823 - val_loss: 0.5023 - val_accuracy: 0.7600\n",
            "Epoch 8/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.1971 - accuracy: 0.9165 - val_loss: 0.5295 - val_accuracy: 0.7600\n",
            "Epoch 9/12\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.1392 - accuracy: 0.9538 - val_loss: 0.5298 - val_accuracy: 0.7867\n",
            "Epoch 10/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.1414 - accuracy: 0.9449 - val_loss: 0.5350 - val_accuracy: 0.8400\n",
            "Epoch 11/12\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.1131 - accuracy: 0.9717 - val_loss: 0.5862 - val_accuracy: 0.8000\n",
            "Epoch 12/12\n",
            "21/21 [==============================] - 2s 75ms/step - loss: 0.0809 - accuracy: 0.9747 - val_loss: 0.6685 - val_accuracy: 0.7467\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6684826612472534, 0.746666669845581]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}
